{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kp2d import KP2D\n",
    "from kp2d.utils import *\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_photo_list(image_directory):\n",
    "    nms = []\n",
    "    ext = []\n",
    "    for file in os.scandir(image_directory):\n",
    "        nms.append(file.name[:-4])\n",
    "        ext.append(os.path.splitext(file.path)[1])\n",
    "    if len(set(ext)) == 1:\n",
    "        ext = ext[0]\n",
    "    else:\n",
    "        print('Ошибка! В папке не только картинки, или они разного формата.')\n",
    "    photo_list = [name for name in nms]\n",
    "    photo_list.sort(key=float)\n",
    "    return photo_list, ext\n",
    "\n",
    "def panorama(input_path, output_path, SIFT=False, rotate=False):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if SIFT:\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "        reprojThresh = 4\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "\n",
    "    else:\n",
    "        use_gpu = True\n",
    "        min_score = 0.7\n",
    "        model_path = \".\\models\\keypoint_resnet.ckpt\"\n",
    "        reprojThresh = 4\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "\n",
    "\n",
    "    \n",
    "    photo_list, ext = create_photo_list(input_path)\n",
    "\n",
    "\n",
    "    query_image = cv2.imread(\n",
    "        os.path.join(input_path , photo_list[0]+ext))\n",
    "    if rotate:\n",
    "        query_image = cv2.rotate(query_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "\n",
    "    if SIFT:\n",
    "        query_keypoints, query_features = descriptor.detectAndCompute(query_image, None)\n",
    "        perimeter_ratio = 1\n",
    "\n",
    "    else:\n",
    "        input_size = (query_image.shape[1], query_image.shape[0])\n",
    "        keypoint_detector = KP2D(model_path, input_size, min_score, use_gpu)\n",
    "        query_scores, query_keypoints, query_features = keypoint_detector(query_image)\n",
    "        perimeter_ratio = 1\n",
    "\n",
    "    perimeter_x = query_image.shape[1] * perimeter_ratio\n",
    "    perimeter_y = query_image.shape[0] * perimeter_ratio\n",
    "\n",
    "    filtered_keypoints = [kp for kp in query_keypoints if (kp.pt[0] <= perimeter_x) or (kp.pt[0] >= query_image.shape[1] - perimeter_x) or\n",
    "                        (kp.pt[1] <= perimeter_y) or (kp.pt[1] >= query_image.shape[0] - perimeter_y)]\n",
    "    filtered_indices = [i for i, kp in enumerate(query_keypoints) if kp in filtered_keypoints]\n",
    "    filtered_features = query_features[filtered_indices]\n",
    "\n",
    "    homography_list = []\n",
    "    corner_points_x = [0, query_image.shape[1]]\n",
    "    corner_points_y = [0, query_image.shape[0]]\n",
    "\n",
    "    keypoints_xy = np.float32([[kp.pt[0], kp.pt[1]] for kp in filtered_keypoints])\n",
    "\n",
    "    for num_photo, photo in enumerate(photo_list[1:], start=1):\n",
    "        train_image = cv2.imread(os.path.join(input_path , photo+ext))\n",
    "        if rotate:\n",
    "            train_image = cv2.rotate(train_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "\n",
    "        if SIFT:\n",
    "            train_keypoints, train_features = descriptor.detectAndCompute(train_image, None)\n",
    "        else:\n",
    "            train_scores, train_keypoints, train_features = keypoint_detector(train_image)\n",
    "\n",
    "        perimeter_x = train_image.shape[1] * perimeter_ratio\n",
    "        perimeter_y = train_image.shape[0] * perimeter_ratio\n",
    "\n",
    "        filtered_keypoints_2 = [kp for kp in train_keypoints if (kp.pt[0] <= perimeter_x) or (kp.pt[0] >= train_image.shape[1] - perimeter_x) or\n",
    "                            (kp.pt[1] <= perimeter_y) or (kp.pt[1] >= train_image.shape[0] - perimeter_y)]\n",
    "        filtered_indices_2 = [i for i, kp in enumerate(train_keypoints) if kp in filtered_keypoints_2]\n",
    "        filtered_features_2 = train_features[filtered_indices_2]\n",
    "\n",
    "        knn_matches = matcher.knnMatch(filtered_features_2, filtered_features, 2)\n",
    "        \n",
    "\n",
    "        ratio_thresh = 0.75\n",
    "        good_matches = [m for m, n in knn_matches if m.distance < ratio_thresh * n.distance]\n",
    "\n",
    "        obj = np.float32([filtered_keypoints_2[m.queryIdx].pt for m in good_matches])\n",
    "        scene = keypoints_xy[[m.trainIdx for m in good_matches]]\n",
    "\n",
    "        H, _ = cv2.findHomography(obj, scene, cv2.RANSAC, reprojThresh)\n",
    "        homography_list.append(H)\n",
    "\n",
    "        h, w, _ = train_image.shape\n",
    "        corners_bef = np.float32([[0, 0], [w, 0], [w, h], [0, h]]).reshape(-1, 1, 2)\n",
    "        corners_aft = cv2.perspectiveTransform(corners_bef, H)\n",
    "        c = corners_aft.reshape(-1, 2)\n",
    "        corner_points_x.extend([c[0, 0], c[1, 0], c[2, 0], c[3, 0]])\n",
    "        corner_points_y.extend([c[0, 1], c[1, 1], c[2, 1], c[3, 1]])\n",
    "\n",
    "        kps_first2 = np.float32([[kp.pt[0], kp.pt[1]] for kp in filtered_keypoints_2])\n",
    "        corners_bef = kps_first2.reshape(-1, 1, 2)\n",
    "        corners_aft = cv2.perspectiveTransform(corners_bef, H)\n",
    "        c = corners_aft.reshape(-1, 2)\n",
    "        keypoints_xy = np.vstack([keypoints_xy, c])\n",
    "        filtered_features = np.vstack([filtered_features, filtered_features_2])\n",
    "\n",
    "    time_1 = time.time() - start_time\n",
    "\n",
    "    x_min = min(corner_points_x)\n",
    "    x_max = max(corner_points_x)\n",
    "    y_min = min(corner_points_y)\n",
    "    y_max = max(corner_points_y)\n",
    "\n",
    "    delta_x = int(x_max - x_min)\n",
    "    delta_y = int(y_max - y_min)\n",
    "\n",
    "    result = np.zeros((delta_y, delta_x, 3), dtype=np.uint8)\n",
    "    result[0:query_image.shape[0], 0:query_image.shape[1]] = query_image\n",
    "\n",
    "    for num_photo, photo in enumerate(photo_list[1:], start=1):\n",
    "        train_image = cv2.imread(\n",
    "            os.path.join(input_path , photo+ext))\n",
    "        if rotate:\n",
    "            train_image = cv2.rotate(train_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "        temp = cv2.warpPerspective(train_image, homography_list[num_photo - 1], (delta_x, delta_y), borderMode=cv2.BORDER_TRANSPARENT)\n",
    "        nonzero_pixels = np.bitwise_and(np.any(temp, axis=2), np.bitwise_not(np.any(result, axis=2)))\n",
    "        result[nonzero_pixels] = temp[nonzero_pixels]\n",
    "\n",
    "    all_time = time.time() - start_time\n",
    "    cv2.imwrite(os.path.join(output_path), result)\n",
    "    print(all_time)\n",
    "    print(\"Only the second loop: \", all_time - time_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 1: панорама из видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала собираю кадры из видео, сохраняю и соединяю в панораму\n",
    "\n",
    "for i, video in enumerate(os.scandir('examples\\\\vids\\\\vids')):\n",
    "    print(video.path)\n",
    "    save_best_frames_from_video(video.path, 'examples\\\\vids\\\\vid_img_out\\\\test', 8, 50)\n",
    "    name = str(i).zfill(6)\n",
    "    panorama('examples\\\\vids\\\\vid_img_out\\\\test', f'examples\\\\vids\\\\vid_img_out\\\\{name}.png',False)\n",
    "    shutil.rmtree('examples\\\\vids\\\\vid_img_out\\\\test')\n",
    "\n",
    "# Так как видео в довольно высоком разрешении и снято горизонтальными линиями,\n",
    "# я поворачиваю и уменьшаю получившиеся кусочки \n",
    "for dirent in os.scandir('examples\\\\vids\\\\vid_img_out'):\n",
    "    print(dirent.name)\n",
    "    img = cv2.imread(dirent.path)\n",
    "    img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "    width = int(img.shape[1] * 50 / 100)\n",
    "    height = int(img.shape[0] * 50 / 100)\n",
    "    dim = (width, height)\n",
    "    img = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite(f'examples\\\\vid_img_out\\\\{dirent.name}', img)\n",
    "panorama('examples\\\\vid_img_out', 'examples\\\\vids\\\\video_result.png')\n",
    "# к сожалению, результат панорамы из видео получился недостаточно хорошим, но это следствие того, что неровно было снято видео\n",
    "video_result = cv2.imread('examples\\\\vids\\\\video_result.png')\n",
    "cv2.imshow('video result', video_result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 2: панорама из фото"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4846904277801514\n",
      "Only the second loop:  0.906195878982544\n"
     ]
    }
   ],
   "source": [
    "# на ровно сфотографированной карте результат получается следующим\n",
    "panorama('examples\\img_input', 'examples\\output\\photo_res.png',False)\n",
    "result = cv2.imread('examples\\output\\photo_res.png')\n",
    "cv2.imshow('photo result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
